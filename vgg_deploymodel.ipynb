{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import AzureCliAuthentication\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "cli_auth = AzureCliAuthentication()\n",
    "ws = Workspace(subscription_id='401a2f63-c029-433e-9087-c839197089fd', resource_group='pix2para_resourcegroup', workspace_name = 'pix2para', auth=cli_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'vgg_test'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pix2para': [Workspace.create(name='pix2para', subscription_id='401a2f63-c029-433e-9087-c839197089fd', resource_group='pix2para_resourcegroup')]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.list(subscription_id = '401a2f63-c029-433e-9087-c839197089fd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target: cpu-cluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print(\"found compute target: \" + compute_name)\n",
    "else:\n",
    "    print(\"creating new compute target...\")\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "   \n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), \"vggtest\")\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/vgg.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "import joblib\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "model = VGG19()\n",
    "joblib.dump(value=model, filename='outputs/vgg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "model = VGG19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "#right one\n",
    "import json \n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.vgg19 import decode_predictions\n",
    "from keras.applications.vgg19 import VGG19\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image\n",
    "import json\n",
    "from numpy import array\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model = VGG19()\n",
    "    \n",
    "def run(image_bytes):\n",
    "    image_bytes = json.loads(image_bytes)['data'] #str to string\n",
    "    image_bytes = image_bytes.encode('utf-8')\n",
    "    image = Image.frombytes('RGBA', (224,224), image_bytes, 'raw')\n",
    "    image = image.resize((224,224),Image.ANTIALIAS)    \n",
    "    image = img_to_array(image)\n",
    "    image = image[:,:,0:3]\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    yhat = model.predict(image)\n",
    "    label = decode_predictions(yhat)\n",
    "    label = label[0][0][1]\n",
    "    #return(str(type(label)))\n",
    "    return label\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "b'{\"data\":\"iVBORw0KGgoAAAANSUhEUgAABSIAAAPYCAYAAADO8YdiAAAgAElEQVR4Aay9W5IeSbKkh0t1833IVfCZT1zeWezZwAh'\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'bytes'>\n",
      "1823572\n",
      "<class 'PIL.Image.Image'>\n",
      "[130, 130, 130, 255, 130, 130, 130, 255, 104, 104]\n",
      "(224, 224, 3)\n",
      "<class 'str'>\n",
      "poncho\n"
     ]
    }
   ],
   "source": [
    "#debugging cell: ignore\n",
    "#test to check for score.py runtime errors\n",
    "import base64\n",
    "import json \n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.vgg19 import decode_predictions\n",
    "from keras.applications.vgg19 import VGG19\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image\n",
    "import json\n",
    "from numpy import array\n",
    "import struct\n",
    "\n",
    "def run(image_bytes):\n",
    "    \n",
    "    #data = np.array(image)\n",
    "    # make prediction\n",
    "    print(type((image_bytes)))\n",
    "    #print(image_bytes[0:100])\n",
    "    image_bytes = image_bytes.encode()\n",
    "    #print(type((image_bytes)))\n",
    "    print(image_bytes[0:100])\n",
    "    \n",
    "    image_bytes = json.loads(image_bytes)['data']\n",
    "    print(type((image_bytes)))\n",
    "    #image_bytes = struct.unpack('d', image_bytes)[0]\n",
    "    print(type((image_bytes)))\n",
    "    image_bytes = image_bytes.encode('utf-8')\n",
    "    print(type((image_bytes)))\n",
    "    encode_len = len(image_bytes)\n",
    "    print(encode_len)\n",
    "    \n",
    "    image = Image.frombytes('RGBA', (263,128), image_bytes, 'raw')\n",
    "    print(type(image))\n",
    "    image = image.resize((224,224),Image.ANTIALIAS)\n",
    "    pilimg = list(Image.open(image_path, 'r').getdata())\n",
    "    #pix_val_flat = [x for sets in pilimg for x in sets]\n",
    "    print(pix_val_flat[0:10])\n",
    "    image.show()\n",
    "    \n",
    "    image = img_to_array(image)\n",
    "    image = image[:,:,0:3]\n",
    "    print(image.shape)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    \n",
    "    model = VGG19()\n",
    "    yhat = model.predict(image)\n",
    "    label = decode_predictions(yhat)\n",
    "    label = label[0][0][1]\n",
    "    print(type(label))\n",
    "    return label\n",
    "\n",
    "\n",
    "'''image_path = '/Users/audreycui01/New Unity Project/assets/screenshot.png'\n",
    "image = Image.open(image_path, 'r')\n",
    "#image.show()\n",
    "pilimg = list(image.getdata())\n",
    "#pix_val_flat = [x for sets in pilimg for x in sets]\n",
    "print(pilimg[0:100])\n",
    "print(array(pilimg).shape)\n",
    "#image_bytes = base64.b64encode(pix_val_flat)\n",
    "image_bytes = bytearray(pix_val_flat)\n",
    "image_bytes = str(image_bytes)\n",
    "#image_bytes = image_bytes.decode('utf-8')'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(image_path, \"rb\") as imageFile:\n",
    "    image_bytes = bytes(imageFile.read())\n",
    "    #image_bytes = image_bytes.decode('utf-8')\n",
    "#image_bytes = image_bytes.encode('utf-8')\n",
    "#image = Image.frombytes('RGBA', (224,224), image_bytes, 'raw')\n",
    "\n",
    "#decode_len = len(image_bytes)\n",
    "#print(decode_len)\n",
    "#data = {\"data\": [image_bytes]}\n",
    "#input_data = json.dumps(data)\n",
    "#print(input_data[0:100])\n",
    "\n",
    "scorejson_path = '/Users/audreycui01/New Unity Project/assets/scoreJson.txt'\n",
    "with open(scorejson_path, \"rb\") as sj: \n",
    "    scorejson = sj.read()\n",
    "scorejson = scorejson.decode()\n",
    "label = run(scorejson)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model_name = \"vggtest\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model vggtest\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model = Model.register(model_path=\"outputs/vgg.pkl\",\n",
    "                        model_name=model_name,\n",
    "                        description=\"vgg test\",\n",
    "                        workspace=ws)\n",
    "#model.download(target_dir=os.getcwd(), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_pip_package(\"scikit-learn==0.22.1\")\n",
    "myenv.add_pip_package(\"keras.applications\")\n",
    "myenv.add_pip_package(\"keras.preprocessing\")\n",
    "myenv.add_pip_package(\"azureml-defaults\")\n",
    "myenv.add_pip_package(\"keras\")\n",
    "myenv.add_pip_package(\"tensorflow\")\n",
    "myenv.add_pip_package(\"numpy\")\n",
    "myenv.add_pip_package(\"pillow\")\n",
    "\n",
    "\n",
    "with open(\"my_vgg_env.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=8, \n",
    "                                               description='vggtest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running..............................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "CPU times: user 1.17 s, sys: 185 ms, total: 1.35 s\n",
      "Wall time: 5min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "\n",
    "myenv = Environment.from_conda_specification(name=\"my_vgg_env\", file_path=\"my_vgg_env.yml\")\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
    "\n",
    "service = Model.deploy(workspace=ws, \n",
    "                       name='vggtest', \n",
    "                       models=[model], \n",
    "                       inference_config=inference_config, \n",
    "                       deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = AciWebservice(ws, 'vggtest')\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
    "myenv = Environment.from_conda_specification(name=\"my_vgg_env\", file_path=\"my_vgg_env.yml\")\n",
    "\n",
    "service.update(inference_config = inference_config)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://17ebffef-bd8b-43dc-bb83-4649983647cc.westus.azurecontainer.io/score\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)\n",
    "print(service.state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
